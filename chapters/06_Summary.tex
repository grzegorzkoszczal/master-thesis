\chapter{Summary and future work}

\section{Summary}

The goal of this master thesis was to conduct experiments and compare various
methods of power draw measurements of computational nodes. The idea came from
the fact, that the ICT sector holds a fair share in global electricity usage
and this contribution will rapidly grow in the near future. Therefore, data
centers responsible with major energy usage are more prone to shift their
focus on the so-calles \emph{green computing}, where the performance of the
computations meets the lower energy consumption. In order to achieve this,
a precise power measurements tools are necessary, so any changes such as
kernels optimization or power-capping can be verified as a~proper solutions
for lowering the energy usage.

For the purpose of the tests, two software measurements tools provided by the
major CPUs and GPUs manufacturers were compared againt external power meter
in order to check their reliability. The software tools used are Intel RAPL,
wrapped conveniently in Linux Perf toolkit for the measurements of the Intel
CPUs and NVIDIA Management Library for the measurements of the NVIDIA GPUs.
As a ground truth, the Yokogawa WT310E Power Meter has been used $-$ certified
and reliable source of the power measurements of the entire computational
nodes.

Later in this work, the benchmarks were discussed $-$ set of programs that
are designed to help evaluate the performance of parallel supercomputers.
Their main goal is to put the testsed devices under strain and fully utilize
their resources. After set of preliminary tests, benchmarks chosen for the
final tests uses different implementations and solves various problems with
different input sizes, all in order to recreate diverse computational problems
that could be faced during the tests in data centers.

Next, the three research papers are presented as a part of the `related works'
section. This gives the insight on methodology used by the scientists that
conducted similar experiments. Such research allows to learn more about the
topic and gives hints on how the tests should be correctly executed.

For the clarity of the work, an exhausting overview on all of the
configurations used in experiments was given. Every setup has been sorted
in ordered manner: server, device, implementation, benchmark and configuration.
This approach helps to get grasp on the used solutions and helps in organizing
and writing the \emph{scheduler} script, that was responsible for the
automation of the experiments. The individual parts of the script has been
then thoroughly explained, both the workflows of the application and the
tasks performed by the implemented functions.

Finally, the measurements data has been presented in form of convenient tables.
The first set of tables shows the power draw and energy consumption of both
individual devices and the entire node as a whole. It gives a very precise
informations about every components used during tests, with values accompanied
with the standard deviations, that helps to describe how dispersed these sets
of data are. For a better overview on the differences between power draw
of active node during during tests and base values of power draw from idle
node, a set of summary tables has been created. Based on the information
they include, the analysis of the entire experiment has been done.
As a final remark, the best solution for measurements of the power draw of the
entire server is to use external power meter $-$ this way one can be sure that
estimates of the energy usage are as close to the real values as possible, due
to the fact, that the power draw of components other than CPUs and GPUs are
also included. The devices such as RAM sticks, motherboard, fans tends to
increase their power usage, the more of the CPUs and GPUs resources are being
utilized during tests. In case of the software measurements tools, they seems
to be very useful for gathering information about device specific power draw
and by analysing the mentioned in previous chapter \emph{offset} and
\emph{percentage increase in power draw during tests}, they behave predictably,
showing rather linear increases, based on the more resources used. The only
configurations that shows concerns are the GPUs and Hybrid benchmarks
executed on \emph{sanna.kask}, where the surges of power draw could be
observed in configurations with 4 and 8~GPUs. As of the reason for what 
causes such behaviour, further investigation would be required in the
future works.



\section{Future work}

In the terms of future work, this master thesis gives a strong insights for
further expansion of the experiments.

One of the ideas is to perform tests
on different node with more diverse components, such as different CPUs and
GPUs, than those tested, to check if the results can be repeated and compared
with already performed experiments. Other idea is to perform tests on both 
\emph{sanna.kask} and \emph{vinnana.kask} nodes simultaneously, using the
MPI and Horovod based benchmarks, due to their inter-node communication.
This approach would simulate running benchmarks on a HPC cluster. For
the configurations of this setup, it is a sound strategy to run the tests
utilising significant amount of the resources, such as tests on half of the
devices and then, utilising all of them on both servers. This will avoid
the repetition of already performed experiments and focus solely on
researching the behaviour of the nodes under high computational strain.

Another good idea is to use Linux Perf to gather the information about energy
consumption of the RAM of the servers. This would reduce the uncertainty of
the measurements done by Yokogawa WT310E on the entire nodes, giving more
informations about the behaviour of the servers power draw during tests,
therefore allowing to receive more precise results and form even better
conclusions.

Due to the fact, that many tests using different benchmarkshas has been
performed on various configurations, starting from the single thread benchmarks,
through the multi-CPUs and multi-GPUs and the finally hybrid benchmarks
utilizing all the resources available on the servers, another solution has been
proposed. Future goal is to create an empirical model, that will give insight
about how much will increase the difference between readings from the Yokogawa
external power meter and software solutions, such as Linux Perf and NVML\@.
The purpose of such model would be rapidly checking the link of the 
entire node power draw and the sum of power draws of active CPUs and GPUs.

Other suggestion is to give more attentions to the PSUs used in order to
power the servers. Many PSUs have different certifications, such as
\emph{Bronze}, \emph{Silver}, \emph{Gold}, \emph{Platinum} and \emph{Titanium}.
Their main difference is their energy efficiencies at various load levels.
The least efficient are the PSUs with \emph{Bronze} certification, while the
best are \emph{Titanium} ones. This could discover potential differencies
in the readings of power draw of the servers and could also benefit in
fine-tuning the previously mentioned empirical model.

As the culmination of this work, there is a high potential in writing
a research paper that would containg the most insightful informations
and conclusions made afer the tests. As a motivation for this idea it should
be noted, that this master thesis contains very exhausting experiments part,
with various implementations, benchmarks and class sizes tested as well as
meaningful conclusions drawn form the tests, than paired with previously
mentioned ideas for the expansion of the experiments, can form a strong base
for the research paper. The topic of energy aware computing is currently
very popular, due to increase of electricity use by the ICT sector world-wide,
and the rising demand of the \emph{green computing}, that has in mind finding
the best ratio of performance to energy use. Research paper based on this work
could contribute to this idea, due to verification of the software measurements
method upon which the power draw of the computational nodes is estimated.