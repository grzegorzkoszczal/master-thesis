\chapter{Theoretical background}

\section{Measurement software}

\subsection{Intel RAPL}

Intel RAPL (Running Average Power Limit)
~\cite{Power_Management_on_Intel_Microprocessor} is an interface
~\cite{RAPL_Power_Estimation_and_Capping}, which allows
software to set a power limit that hardware ensures and any
power control system takes it as an input and tunes behavior
to ensure that this operating limit is respected.
That way, it is possible to set and monitor power limits both
on processor and DRAM, and by controlling the maximum average
power, it matches the expected power and cooling budget. RAPL
exposes its energy counters through model-specific registers
(MSRs) It updates these counters once in every 1 ms. The energy
is calculated as a multiple of model specific energy units.
For Sandy Bridge, the energy unit is 15.3 µJ, whereas it is 61
µJ for Haswell and Skylake.

Moreover, the Intel RAPL divides the platform into four domains,
which consists of:

\begin{itemize}
    \item PP0 (Core Devices) $-$ Includes the energy consumption
    by all the CPU cores in the socket\@(s).
    \item PP1 (Uncore Devices) $-$ Includes the power consumption
    of integrated graphics processing unit (unavailable on the
    server platforms)
    \item DRAM $-$ The energy consumption of the main memory.
    \item Package $-$ The energy consumption of the entire socket
    including core and uncore.
\end{itemize}

\subsection{NVIDIA NVML}

NVIDIA Management Library (NVML)~\cite{NVML} $-$ A C-based API
for monitoring and managing various states of the NVIDIA GPU
devices. It provides direct access to the queries and commands
exposed via nvidia-smi~\cite{NVIDIA_SMI}.
The runtime version of NVML ships
with the NVIDIA display driver, and the SDK provides the
appropriate header, stub libraries and sample applications.
Each new version of NVML is backwards compatible and is intended
to be a platform for building third party applications.

There are various techniques of computing the energy consumption
using the NVIDIA Management Library, which query the onboard
sensors and read the power usage of the device. Such techniques
are either from the native NVML API, like Sampling Monitoring
Approach (SMA) or Multi-Threaded Synchronized Monitoring (MTSM)
or from CUDA component and it's called Performance Application
Programming Interface (PAPI)~\cite{PAPI_CUDA}.

Sampling Monitoring Approach (SMA) $-$ The C-based API provided
by NVML that can query the power usage of the device and provide
an instantaneous power measurement. Therefore, it can be
programmed to keep reading the hardware sensor with a certain
frequency. The \emph{nvmlDeviceGetPowerUsage\@()} function is
used to retrieve the power usage reading for the device, in
milliwatts. This function is called and executed by the CPU\@.
The highest frequency possible is 66.7 Hz, which means the
measurements are done every 15 ms.

Performance Application Programming Interface (PAPI) provides
an API to access the hardware performance counters found on
modern processors. The various performance metrics can be read
through simple programming interfaces from C or Fortran. It
could be used as a middleware in different profiling and tracing
tools. PAPI can work as a high-level wrapper for different
components. Previously it used only Intel RAPL's interface to
report the power usage and energy consumption for Intel CPUs,
but recent updates added the NVML component, which supports
both measuring and capping power usage on modern NVIDIA GPU
architectures. The major advantage of using PAPI is that the
measurements are by default synchronized with the kernel execution.
The NVML component implemented in PAPI uses the function,
\emph{getPowerUsage\@()} which query \emph{nvmlDeviceGetPowerUsage\@()}
function. According to the documentation, this function is called
only once when the command “papi end” is called. Thus, the power
returned using this method is an instantaneous power when the
kernel finishes execution.

Multi-Threaded Synchronized Monitoring (MTSM) $-$ this method
differs from SMA approach in the measurement period, a specific,
exact window of the kernel execution is identified which results
in recording of only the power reading of the kernel solely.
Monitoring part is performed by the host CPU in that way the
master thread calls and then monitors the kernel and other
threads records the power, therefore it requires the use of
parallel programming execution models, such as Pthreads
~\cite{Pthreads} or
OpenMP~\cite{OpenMP}. This approach at first initializes the volatile
variable (at master thread) that is used later in recording of
power readings. Then, the remaining threads execute the monitoring
function in parallel and start measuring the time and power draw
as the benchmark kernel starts doing the computation. After its
work is done, the timing is ended and the stored measurements
are synchronized, giving the precise logs of power consumption
during the test period.

\section{Measurement hardware}

\subsection{Yokogawa WT310E}

In order to perform comparison and to check the reliability
of software power measurement methods, such as mentioned
above Intel RAPL or NVIDIA NVML, it is mandatory to use
a certified tool that would serve as the ground truth in
such tests. Such a tool is Yokogawa WT310E $-$ an external
power meter that will serve this purpose in tests in this paper.
It is a digital power analyzer that provides extremely low
current measurement capability down to 50 micro-Amps, and
a maximum of up to 26 Amps RMS\@. This device follows standards
and certificates such as Energy Star®~\cite{EnergyStar},
SPECpower~\cite{SPEC} and IEC62301~\cite{IEC} / EN50564~\cite{iTeh}
testing. This model comes from a WT300E's family of appliances
that offer a wide range of functions and enhanced specifications,
allowing handling of all the measurement applications from low
frequency to high frequency inverters using a single power meter.
The WT300E series with the fast display update rate of 100ms,
offer's engineers a short tact time in their testing procedures.
The basic accuracy for all input ranges is 0.1\% rdg + 0.05\%
rng (50/60Hz) and DC 0.1\% rdg + 0.2\% rng.

To use the Yokogawa WT310E power meter, a special software has
been written for easy use $-$ the Yokotool~\cite{GitHub_intel/yoko-tool}.
Yokotool is a command-line tool for controlling Yokogawa power
meters in Linux. The tool is written in Python and works with both
Python 2.7 and Python 3. The tool comes with the
`yokolibs.PowerMeter' module which can be used from Python scripts.

\newpage

% Here I describe the benchmark applications
\section{Benchmark applications}

For the purpose of the experiments, benchmark applications should
fully utilize the resources of the tested CPUs and GPUs, as well as
be able to run on various configurations parameters. Such parameters
are: being able to run in parallel on various numbers of logical
processors, being able to run on one or more GPUs and being able to
execute on various input parameters class sizes.

There are four benchmark sets, that satisfy mentioned goals:
\begin{itemize}
    \item NAS Parallel Benchmarks (C++ with OMP)
    \item NAS Parallel Benchmarks (Fortran with MPI)
    \item NAS Parallel Benchmarks (CUDA)
    \item Custom deep learning model, based on XCeptionnet with MPI communication
\end{itemize}

In a general sense, the NAS Parallel Benchmarks are a set of programs designed
and created in order to help evaluate the performance of parallel
supercomputers. They are based on computational fluid dynamics applications and
originally consisted of five kernels and three pseudo-applications. Later on,
the benchmark suite has been extended with more kernels, such as adaptive meshes,
parallel I/O, multi-zone applications, and computational grids. Every application
comes with predefined and indicated problem size, labeled as class size.
Moreover, the benchmark kernels are available in widely-used programming
models like MPI and OpenMP, which allows for easy configuration of use with
various number of CPU threads (NPB-OMP and NPB-MPI)~\cite{NPB-CPP}, as well
as execution on two or more computational nodes (NPB-MPI only). For the
computations on GPUs, different set has been created, which excels in tests
on a single devices (NPB-CUDA)~\cite{NPB-CUDA_1}~\cite{NPB-CUDA_2}. In order To
run GPUs benchmarks in multi-GPUs and multi-node environments, a custom deep
learning model has been created solely for the purpose of this task.

Below is listed the original set of eight NPB benchmarks, which are tested later in the
experiments conducted for the purpose of this work.

Five kernels:
\begin{itemize}
    \item \textbf{IS} $-$ Integer Sort (random memory access)
    \item \textbf{EP} $-$ Embarassingly Parallel
    \item \textbf{CG} $-$ Conjugate Gradient (irregular memory access and communication)
    \item \textbf{MG} $-$ Multi-Grid on a sequence of meshes
    \item \textbf{FT} $-$ Discrete 3D fast Fourier Transform (all-to-all communication)
\end{itemize}

Three pseudo applications:
\begin{itemize}
    \item \textbf{BT} $-$ Block Tri-diagonal solver
    \item \textbf{SP} $-$ Scalar Penta-diagonal solver
    \item \textbf{LU} $-$ Lower-Upper Gauss-Seidel solver
\end{itemize}

The three pseudo applications mentioned earlier also come with the multi-zone
versions, designed to exploit multiple levels of parallelism. Moreover, NPB
suite also offers benchmarks for unstructured computation, parallel I/O and
data movement. For the purpose of this work only the original single-zone
kernels and applications were used, therefore these benchmarks suites are
mentioned only.

In addition to solving different computational problems, each kernel or
application operates on various sizes of input data, determined during
compilation, known as classes. Those classes helps choosing the right benchmark
in term of execution time, which helps in measurements. Too short benchmarks may
cause measurement error, due to low sampling rate of measurement instruments and
too long benchmarks are unnecessary, because they prolong the overall experiments.

Benchmark classes:
\begin{itemize}
    \item \textbf{Class S} $-$ Very small, used for quick test purpose. Nowadays obsolete.
    \item \textbf{Class W} $-$ The so-called `90's workstation' size, nowadays consisted small.
    \item \textbf{Classes A, B, C} $-$ Standard test problems ($\sim$4 times size increase from
    each of the previous classes)
    \item \textbf{Classes D, E, F} $-$ Large test problems ($\sim$16 times size increase from
    each of the previous classes)
\end{itemize}


\subsection{NPB for CPU, C++ with OMP}

NAS Parallel Benchmarks for CPU has been ported from Fortran to C++ $-$ a programming
language that has been developed for a long time as an Object-Oriented successor of
a very popular and successful C language. It is a strongly typed, highly portable
language with very high performance, compatibility and excellent yet difficult,
manual memory management, which makes it a grea choice for writing code, that
is meant to use in High Performance Computing, where fast execution times and low
memory usages are among the most important factors. C++ offers also many 
well-optimised libraries to choose from, based on our goals, as well as extensive
amount of documentations and books, explaining the principles of the language.

OpenMP (Open Multi-Processing) is an API (Application Programming Interface)
and set of directives for parallel programming in shared-memory multiprocessing
environments, primarily used for multi-threading. It's designed to simplify
the development of parallel applications by allowing developers to add parallelism
to their code through compiler directives and library functions. OpenMP is
particularly popular in scientific and high-performance computing applications
where performance optimization is crucial.

Since NPB-OMP comes with up to eight benchmarks and each benchmark can be compiled
with various class sizes, it creates a very diverse and flexible test cases to
choose from, depending of our needs. More informations about choosing the correct
configurations for our purposes are explained in Chapter 4: `Proposal of the
Solution'

Another major advantage of these benchmarks are the fact, that after the
compilation, one can be executed and pinned to specific logical processor using
Linux's \emph{taskset} command~\cite{Linux_taskset}, which is mainly used to
set or retrieve the CPU affinity of a running process. In practice, it allows
to set exact number of created benchmark processes and allows to manually pin
them to the desired threads, which gives us the absolute control over choosing
the benchmark configuration and gives us confidence, that they are correctly
executed.

\newpage

\subsection{NPB for CPU, Fortran with MPI}

Another suite of benchmarks created for execution on CPUs $-$ an older set that
was written in the world's first high level programming language, the Fortran.
Fortran has been widely used in scientific, engineering and numerical computing
applications for several decades. Its main advantages such as high performance,
standarized libraries, support for complex numbers and parallel computing makes
it a valuable and reliable choice in numerical and scientific computing to this
day.

MPI (Message Passing Interface), is a standardized and portable message-passing
system designed for parallel and distributed computing. It provides a set of
routines and libraries for high-performance communication and coordination among
processes or tasks in a parallel or distributed computing environment. MPI is
particularly popular in high-performance computing (HPC) and scientific computing,
where large-scale parallelism is essential for solving complex problems. In
contrast to OMP, this implementation provides inter-node communication for
execution of code on several nodes in parallel manner.

Similar to NPB-OMP, this benchmarks suite also comes with many kernels and class
sizes to choose from, but it should be noted, that it does not offer complete
flexibility in therms of choosing the number of processes $-$ some kernels
require a certain number of processes to run which are specified in the code
documentation, and are caused by the way, the implementation was created.

\subsection{NPB for GPU, CUDA}

CUDA (Compute Unified Device Architecture), is a parallel computing platform
and application programming interface (API) developed by NVIDIA Corporation.
CUDA is specifically designed for accelerating general-purpose computational
tasks on NVIDIA GPUs (Graphics Processing Units). It allows developers to harness
the massive parallel processing power of GPUs to accelerate a~wide range of
applications, including scientific simulations, machine learning, image
processing, and more.

Key features and concepts of CUDA include, but are not limited, to:
\begin{itemize}
    \item Parallel Computing Model: CUDA enables developers to write parallel
    code that can be executed on GPUs.
    \item GPU Acceleration: CUDA provides a means to offload computationally
    intensive tasks from the CPU to the GPU\@.
    \item CUDA C/C++ Language Extensions: Developers can write CUDA code using
    C or C++ with CUDA-specific extensions. These extensions allow developers
    to define GPU kernels, which are functions that run in parallel on the GPU\@.
    \item CUDA Toolkit: The CUDA Toolkit includes the CUDA compiler, runtime
    libraries, and development tools. It enables developers to write, compile,
    and optimize CUDA applications.
\end{itemize}

As mentioned in the previously shown CPU implementations, this benchmarks
suite also comes with various kernels and class sizes to choose from, according
to our needs. One important thing should be noted, however $-$ due to the
nature of the way it has been implemented, the index number of the GPU, that
will be used during tests must be specified in the configurations file during
compilation. Therefore this benchmark sets are single-GPU only and require
creation of many executable files with various configs, if the test server
has many GPUs. This problem is explained in more detail and ultimately
resolved in Chapter 4.

\newpage

\subsection{Custom Deep Neural Networks model}

Last benchmark application used in this work fills the remaining gap for test
suite $-$ an multi-GPUs kernel that utilizes MPI and has potential for
multi-node training. This application was created solely for the purpose of
this paper and utilizes high-level deep learning frameworks, such as
TensorFlow and Keras, widely known and used, general-purpose programming
language such as Python, as well as Horovod~\cite{Horovod_IDRIS} framework,
that utilizes MPI and NCCL communication libraries. The mentioned components
used in this benchmark are more precisely described below:

Python is a versatile and widely-used high-level programming language known
for its simplicity, readability, and extensive standard libraries. The fact
that it is a general-purpose language means, that it can be used in various
fields, such as web development, data analysis, scientific computing and
artificial intelligence. Its high-level abstraction provides a clean and
readable syntax and the fact that its an interpreted language means that
there is no need to compile the code before running it, shortening the
time between each tests of new features. Moreover, Python comes with a~large
and comprehensive standard library for basic programming tasks such as file I/O,
regular expressions, networking and data manipulation, and in case if someone
needs more specific libraries, it features an easy solution for installing
additional packages using PIP (Python Index Package).

TensorFlow is a comprehensive deep learning framework that provides low-level
and high-level APIs. While one can use TensorFlow for a wide range of machine
learning and deep learning tasks, it also includes the Keras API as a high-level
component. TensorFlow provides more low-level control, allowing developers to
customize their models and training loops extensively. This is useful for
researchers and engineers who need fine-grained control over model architecture
and training procedures.

Keras is an open-source high-level neural networks API written in Python.
It provides a user-friendly, high-level interface for building and training
neural networks. Keras was designed with simplicity and ease of use in mind.

Both TensorFlow and Keras offers extensive documentations that allows user
to quickly learn the basics of theirs modules and libraries. Moreover,
organizations such as Google~\cite{Google_Machine_Learning_Crash_Course}
or Kaggle~\cite{Kaggle} offers a practical approach in learning such concepts,
especially Kaggle comes with a~wide array of many datasets and exemplary
solutions, created by the community members.

Horovod~\cite{Horovod} is an open-source distributed deep learning framework
designed to make it easier to train machine learning models on distributed
computing environments, such as clusters or cloud-based setups. It was
developed by Uber Engineering and is designed to provide efficient and
scalable distributed training for deep learning models. Horovod is
particularly well-suited for distributed training with popular deep learning
libraries like TensorFlow, PyTorch, and MXNet. Main advantages of Horovod
framework are: large scale distributed training, that allows multi-GPU and
multi-node support, efficient data parallelism, compatibility with deep
learning frameworks, such as TensorFlow and Keras, resource awarness and
dynamic scaling.

The custom deep learning benchmark, created for the purpose of this Master's
Thesis, tackles the problem of image classification. It involves training
a neural network to categorize or classify images into predefined classes
or categories. The goal is to teach the model to recognize patterns and
features in images that distinguish one category from another. This problem
is commonly addressed using supervised learning, where the neural network
learns from a labeled dataset containing examples of images and their
corresponding class labels. The dataset used has been taken from the Kaggle
website~\cite{Kaggle_Dataset} classes of the dataset represents various
species of birds, that are labeled. The birds in nearly all images occupy
over 50\% of the image, the photos themselves are of good quality $-$ no images
are blurry, done in bad lighting or misslabeled. All images are 224 $\times$
224 $\times$ 3 color images in \@.jpg format. Considering all the informations
about the dataset mentioned above, one can expect a good results when training
deep neural networks models on it. During the tests and fine-tuning phase of
the creation of the model, a very high accuracy of over 90\% has been achieved
in relatively small number of iteration. What is more important in the terms
of this work, the utilization of the GPUs and their power draw has been very
high, thus meeting the requirement for a good benchmark application, to use
possibly as much of the devices resources during measurements as possible.
Main features in this benchmark, that allowed to achieve such great results
are: usage of Horovod innate function to automatically allocate memory growth
based on chosen number of devices, Horovod handling the deep learning
distributed optimizer among the devices via callbacks, TensorFlow's
\emph{.cache\@()} and \emph{.prefetch\@()} utilizing maximum of GPUs VRAM and
finally, usage of XCeption Model $-$ a deep convolutional neural network
architecture that involves Depthwise Separable Convolutions, that has been
developed mainly for the purpose of solving the images classification problems.

% State-of-the-art chapter
\section{Related works}

% First research paper
\subsection{`A Comparative Study of Methods for Measurement
of Energy of Computing'}

Authors of this work~\cite{State_of_the_Art_Article_1}
investigated the accuracy of measurement of energy consumption
during an application execution in order to ensure the
application-level energy minimization techniques.
They mentioned three most popular methods of measurement:
(a) System-level physical measurements using external power meters;
(b) Measurements using on-chip power sensors and (c) Energy
predictive models. Later, they presented a comparison of the
state-of-the-art on-chip power sensors as well as energy
predictive models against system-level physical measurements
using external power meters, which played the role of a credible
measurement appliance.

The methodology is as follows: The ground truth tests were
performed at first, using WattsUp Pro
Meter~\cite{WattsUp_Quick_Reference_Guide}. The group of
components that were running the benchmark kernel were defined
as abstract processor $-$ a whole that consists of multicore CPU
processor, consisting of a certain number of physical cores and
DRAM\@. In order to perform meaningful measurements, only a~certain
configuration of application was run, that executed solely on an
abstract processor, without need of using any other system
resources, such as solid state drives or network interface cards
and so on. The result of such an approach is that HCLWattsUp
reflects solely the power drawn from CPU and DRAM\@.

The researchers took other important precautions during the
experiment. At first, all the resources they used have been
reserved and fully dedicated to the experiment, making sure
that no unwanted, third-party applications are being run in
the background. During the tests, they actively monitored the
disk consumption and network to ensure that there is no
interference in the measurements. Another important factor of
the testbed that draws power and generates heat are the fans.
In default configuration, the fans speed is dependent on the
increasing temperature of the CPUs, which rises as the time of
the training goes on. That generates a dynamic energy consumption
that impacts negatively on the outcomes of the experiment.
To rule this phenomenon out, all the fans in the entire testbed
are set at full speed, therefore they draw the same amount of
power regardless of the actual strain put on CPUs and their
temperature. All the procedures mentioned above ensure that the
dynamic energy consumption obtained using HCLWattsUp, reflects
the contribution solely by the abstract processor executing the
given application kernel.

After determining the “ground truth” measurements using the
configuration with HCLWattsUp, the researchers conducted a series
of tests that determined the dynamic energy consumption by the
given application using RAPL\@. At first the Intel PCM/PAPI was
used to obtain the base power of CPUs, both core and uncore as
well as DRAM, with no straining workload applied. Then, in the
next phase, using HCLWattsUp API the execution time of the given
application has been obtained. After that, the Intel PCM/PAPI has
been used in order to obtain the total consumption of the CPUs and
DRAM, all within the execution time of a given benchmark. Lastly,
the researchers responsible for the experiment calculated the
dynamic energy consumption of the abstract processor by subtracting
the base energy from the total energy drawn during the kernel
execution. To determine the dynamic energy consumption using
HCLWattsUp, all the steps mentioned before has been repeated,
but using the HCLWattsUp software instead of the Intel RAPL\@.

The execution time of the benchmark kernels were the same for
both of the power draw measurement tools, so any difference
between the energy readings of the tools comes solely from
their power readings. Finally, tests were conducted on three
different sets of experiments in order to receive three different
types of patterns.

In the first set of experiments, the FFTW and MKL-FFT energy
consumption has been explored, by using a given workload size.
For many tests on various problem sizes, the Intel RAPL reports
showed less dynamic energy consumption for all application
configurations than HCLWattsUp, but it follows the same pattern
as HCLWattsUp for most of the data points. Therefore it is
possible to calibrate the RAPL readings, which resulted in
significant decrease of average error for the dynamic energy
profile.

Second set of tests was conducted using OpenBLAS DGEMM\@.
Executions were, again, performed using various configurations
of data sizes, but results were less satisfactory than in the
first tests. Like the first set of experiments, RAPL profiles
lag behind the HCLWattsUp profiles. Unlike the first set of
experiments where the error between both the profiles could be
reduced significantly by calibration, the reduction of the average
error for most of the application configurations was only as
half as effective contrary to the first set of tests. This
calibration, however, is again not the same for all the application
configurations.

In the third and last set of experiments the team studied the
dynamic energy behavior of FFTW as a function of problem size
N x N. The tests were performed in different problem ranges.
Researchers claim that for many data points, RAPL reports an
increase in dynamic energy consumption with respect to the
previous data point in the profile whereas HCLWattsUp reports
a~decrease and vice versa. Therefore it is impossible to use
calibration to reduce the average error between the profiles
because of their interlacing behavior.

As a conclusion, readings from Intel RAPL and HCLWattsUp differ
strongly based on executed benchmark and data size. In the first
set of experiments, the FFTW and MKL-FFT energy consumption test,
the Intel RAPL readings followed the pattern of HCLWattsUp
readings, being even more accurate after calibrations. The second
test however, showed that RAPL does not follow most of the energy
consumption pattern of the power meter. This could be tuned to
some extent by calibration, but not as good as in the first test
case. In the last experiment, however, the RAPL does not follow
the energy consumption pattern of the power meter and can not be
calibrated, leaving the readings quite troublesome.

Next experiment conducted in this paper was the comparison of
measurements by GPU and Xeon Phi Sensors with HCLWattsUp. The
methodology of work is similar to the one explained before $-$ the
entire testbed is reserved solely for the purpose of the
experiment, the fans are set to the maximum speed and only the
abstract processor is measured. To strain the hardware, two
applications were used:

The first one was the matrix multiplication (DGEMM), the second
one was 2D-FFT\@. Tests were performed on two NVIDIA GPUs: K40c
~\cite{Implementation_for_Accelerator_Kernels} and P100,
and one Intel coprocessor, the Intel Xeon Phi 3120P
~\cite{Intel_Xeon_Phi_Coprocessor_Architecture}.
To obtain the power values from on-chip sensors on NVIDIA GPUs,
the dedicated libraries were used, called NVIDIA NVML
~\cite{NVML_Reference_Manual} and
to obtain power values from Intel Xeon Phi, the Intel System
Management Controller chip
(SMC)~\cite{Intel_Xeon_Phi_Coprocessor_Developer} was used.
Values from the
Intel Xeon Phi can be programmatically obtained using Intel
manycore platform software stack (MPSS) [17]. The methodology
taken to compare the measurements using GPU and Xeon Phi sensors
and HCLWattsUp is similar to this for RAPL\@. Briefly, HCLWattsUp
API provides the dynamic energy consumption of an application
using both CPU and an accelerator (GPU or Xeon Phi) instead of
the components involved in its execution. Execution of an
application using GPU/Xeon Phi involves the CPU host-core, DRAM
and PCIe to copy the data between CPU host-core and GPU/Intel
Xeon Phi. On-chip power sensors (NVML and MPSS) only provide
the power consumption of GPU or Xeon Phi only. Therefore, to
obtain the dynamic energy profiles of applications, the Intel
RAPL was used to determine the energy contribution of CPU and
DRAM\@. Energy contributions from data transfers using PCIe were
considered as not significant.

At first, the DGEMM was used as the test benchmark with various
workload sizes. The energy readings from the GPU NVIDIA K40c
sensors exhibit a linear profile whereas HCLWattsUp does not.
Moreover, the sensor does not follow the application behavior
exhibited by HCLWattsUp for approximately two-thirds of the data
points. In the case of the Intel Xeon Phi coprocessor, the results
seemed to be better $-$ sensors follow the trend exhibited by
HCLWattsUp for third-fourth of the data points. However, sensors
report higher dynamic energy than HCLWattsUp, but that can be
reduced significantly using calibration.

In the case of the second benchmark, the 2D-FFT, the measurements
by NVML follow the same trend for the majority of the data points,
compared to the results from NCLWattsUp. The sensor of the Intel
Xeon Phi followed the trend of HCLWattsUp for over 90\% of all
data points, which is a good result. Overall, Intel RAPL and NVML
both exhibit the same trend for FFT\@. Therefore, the difference
with HCLWattsUp comes from both sensors collectively.

The results of this test allows to draw several conclusions.
First, the average error between measurements using sensors and
HCLWattsUp can be reduced using calibration, which is,
nevertheless, specific for an application configuration. Another
important finding is that CPU host-core and DRAM consume equal
or more dynamic energy than the accelerator for FFT applications
(FFTW 2D and MKL FFT 2D),which means that data transfers (between
CPU host-core and an accelerator) consume same amount of energy
as that for computations on the accelerator for older generations
of NVIDIA Tesla GPUs such as K40c and Intel Xeon Phi such as 3120P.
However, for newer generations of Nvidia Tesla GPUs such as P100,
the data transfers consume more dynamic energy than computations.
It suggests that optimizing the data transfers for dynamic energy
consumption is important.

% Second research paper
\subsection{`Verified Instruction-Level Energy Consumption Measurement
for NVIDIA GPUs'}

Authors of this research paper~\cite{State_of_the_Art_Article_2}
investigated the actual cost of the power/energy overhead of
the internal microarchitecture of various NVIDIA GPUs from
four different generations. In order to do so, they compared
over 40 different PTX instructions and showed the effect of
the CUDA compiler optimizations on the energy consumption of
each instruction. To measure the power consumption, they used
three different software techniques to read the GPU on-chip
power sensors and determined their precision by comparing them
to custom-designed hardware power measurement.
The motivation of their work comes from the fact that in order
to increase the performance of the GPUs, their power consumption
must be correctly and reliably measured, because it serves as
a primary metric of performance evaluation. This issue is proven
even more challenging, since the GPU vendors never publish the
data on the actual energy cost of their GPUs' microarchitecture,
therefore the independent research should be conducted in order
to verify the power measurement software they provide.

The authors of the research paper prepared a set of special
micro-benchmarks to stress the GPU, in order to capture the
power usage of each PTX
instruction~\cite{NVIDIA_Parallel_Thread_Execution}, so the
instructions were written in PTX as well. PTX is a virtual-assembly
language used in NVIDIA's CUDA programming environment whose purpose
is to control the exact sequence of instructions executing without
any overhead. The researchers prepared two kernels for the purpose
of this work $-$ first one is tasked with adding integers and second
one responsible for dividing variables with unsigned values.
Since it is impossible to capture power draw of an execution of
a single instruction, a~different approach was proposed: the same
instruction has been repeated millions of times and the power
drawn during the entire test case has been measured. Then the
amount of power reported by the measuring system was divided by
the total number of instructions, giving the power consumed by
a single PTX instruction. It is worth noting that GPUs drain
power as static power and dynamic power. The static power is
a constant power that the GPU consumes to maintain its operation.
To eliminate the static power and any overhead dynamic power
other than the instruction power consumption, the kernel's was
computed twice and the energy consumption was measured both times.
First, the kernel was run in a configuration to measure the total
energy drawn for the operation. In the second run the back-to-back
instructions were omitted and the energy measured was defined as
overhead energy. Energy used on instruction was defined as
subtraction of total energy and overhead energy, divided by the
total number of instructions.

In this experiment, the ground truth of energy drawn by the GPUs
was set by the external power meter. It was pointed out that the
GPUs have two power sources: one is direct DC power, provided by
a PSU, another one is the PCI-E power source, provided through
the motherboard. In order to capture the total power, the
measurement of current and voltage has been done for each power
source simultaneously. A clamp meter and a shunt series resistor
were used for the current measurement. For voltage measurement,
a direct probe on the voltage line using an oscilloscope has been
used. In case of measurements of current and voltage on the direct
DC power supply source, everything was measured using an
oscilloscope, therefore the power draw calculations were performed
using a certain formula. The measurement of the PCI-E power source
was more difficult. Since there wasn't any possibility to directly
receive current or voltage, the authors of this paper decided to
set up a special PCI-E riser board that measures the power supplied
through the motherboard. Two in-series shunt resistors are used as
a power sensing technique. Using the series property, the current
that flows through the riser is the same current that goes to the
graphics card, same with the voltages.

The experiment has been conducted for four NVIDIA GPUs from four
different generations/architectures: GTX TITAN X from Maxwell
architecture, GTX 1080 Ti from Pascal architecture, TITAN V from
Volta architecture and TITAN RTX from Turing architecture. To
compile and run the previously prepared benchmarks, the CUDA NVCC
compiler~\cite{NVIDIA_NVCC} has been used. The results of the
tests show that NVIDIA TITAN V has the lowest energy consumption
per instruction among all the tested GPUs. Additionally the tests
were performed on both CUDA optimized and non-optimized versions
of code, and overall the optimized versions of instruction proved
to be less energy hungry than the non-optimized ones. In terms of
differences between various software power measuring techniques,
namely PAPI versus MTSM, The dominant tendency of the results is
that PAPI readings are always more than the MTSM\@. Although the
difference is not significant for small kernels, it can be up to
1 µJ for bigger kernels like Floating Single and Double Precision
div instructions. Different software techniques (MTSM and PAPI)
have been compared against the hardware setup on Volta TITAN V GPU\@.
Compared to the ground truth hardware measurements, for all the
instructions, the average Mean Absolute Percentage Error (MAPE)
of MTSM Energy is 6.39 and the mean Root Mean Square Error (RMSE)
is 3.97. In contrast, PAPI average MAPE is 10.24 and the average
RMSE is 5.04. The results prove that MTSM is more accurate than
PAPI as it is closer to what has been measured using the hardware.

% Third research paper
\subsection{`Measuring GPU Power with the K20 Built-in Sensor'}

Authors of this research paper~\cite{State_of_the_Art_Article_3}
investigated accurate profiling of the power consumption of
GPU code when using the on-board power sensor of NVIDIA K20 GPUs.
Moreover, two major anomalies that happened during the tests
were more thoroughly analyzed $-$ the first one being related to
the doubling a benchmark kernel's runtime resulted with more
than double energy usage, the second indicated that running two
kernels in close temporal proximity inflates the energy
consumption of the later kernel. Based on previous work in
a similar field and set of preliminary tests, a new, reliable
methodology~\cite{K20Power} has been proposed as the conclusion
of this experiment.

GPUs used in this project are NVIDIA Tesla K20, equipped with
on-board sensors for querying the power consumption at runtime.
As noted by the authors of the work, measurement of the power draw
of the GPU using its built-in sensor is more complex than it would
seem at first glance. The straightforward approach of sampling the
power, computing the average, and multiplying by the runtime of the
GPU code is likely to yield large errors and nonsensical results,
hence the anomalies related to more energy used than expected due
to increase of kernel's runtime or kernel's energy consumption
increase after consecutive runs. Therefore another approach must
be adopted. Methodology of the experiment is as follows: a number
of unexpected behaviors when measuring a GPU's power consumption
have been noted for further investigation, various observations
has been noted during the tests runs conducted on the NVIDIA K20
GPUs and based on those observations and other related work,
a correct way of measuring the power and energy consumption using
sensor has been created. Later on it was validated for reliability
by performing it multiple ways on many GPUs based on Kepler
architecture, equipped with power sensor, such as the NVIDIA K20c,
K20m, and K20x. The custom tool, created by the authors of the
work, has been published for future use by other scientists, as an
open source code.

Benchmark applications used in this paper solved two different
n-body problem implementations. The algorithm models the simulation
of gravity-induced motion of stars in a star cluster. The first
kernel, called NB (N-Body), performs precise pairwise force
calculations, which means that the same operations are performed
for all n bodies, leading to a very regular implementation that
maps well to GPUs. Moreover, the force calculations are
independent, resulting in large amounts of parallelism. The second
code, called BH, uses the Barnes-Hut algorithm to approximately
compute the forces~\cite{O(N)_Force_Calculation_Algorithm}
~\cite{LonestarGPU}. It hierarchically partitions the
volume around the n bodies into successively smaller cubes, called
cells, until there is just one body per innermost cell. The
resulting spatial hierarchy is recorded in an unbalanced octree.
Each cell summarizes information about the bodies it contains. The
NB code is relatively straightforward, has a high computational
density, and only accesses main memory infrequently due to
excellent caching in shared memory. In contrast, the BH code is
quite complex, has a low computational density, performs mostly
irregular~\cite{Irregular_Programs_GPUs_Study} pointer-chasing
memory accesses, and consists of multiple different kernels.
Nevertheless, because of its lower time complexity, it is about
33 times faster than the NB code when simulating one million stars.

In order to conduct the energy measurement from the GPU power
sensor, the authors of the work wrote their own tool to query the
sensor via the NVIDIA Management Library (NVML) interface, which
returns the power readings in milliwatts. The sampling intervals
of the measurement are lowest possible $-$ 15 ms between
measurements. At first, during the tests, there was a noticeable
power lag and measurement distortion $-$ power profiling tends to
lag behind the kernel activity and shape of the profile does not
match the kernel activity in both shape (minor difference) and time
(major difference). The key insight in creating a model of correct
measurement is the fact that the power sensor gradually approaches
the true power level rather than doing so instantly. Since the
`curved' power readings between time when kernel start running and
time when the power curve stabilizes reminded the authors of this
work of capacitors charging and discharging, they tested whether
the power profiles can be described by the same formulas. This
turned out to work very well in the end. It is assumed that this
is the case because the power sensor hardware uses a capacitor of
some sort. After this revelation, the authors determined the 
`capacitance' of the power sensor by using a single capacitor
function to approximate the curve between the kernel start time
and kernel stop time. After that, they determined the value of the
capacitance that minimizes the sum of the differences between the
measured values and the function values. As the capacitance is
constant, it only needs to be established once for a given GPU,
which is C~=~833.333 on all tested K20 GPUs. Computing the true
power draw value then become a single function of the slope of
power profile derived in time domain and is shown in a function
below:

\begin{equation} \label{eq:Computing the true instant power}
    P_{true} (t_i) = P_{meas} (t_i) + C \times (\frac{P_{meas} (t_{i+1}) - P_{meas} (t_{i-1})}{t_{i+1} - t_{i-1}})  [W]
\end{equation}

Moving back onto the recommended steps for this experiment,
following assumption should be considered: highest possible sample
rate for NVML (which is 66.7 Hz / 15 ms between intervals) as well
as including the time stamps, removal of consecutive samples of
the same value that are no more than 4 ms apart of each other,
computation of true power with the equation mentioned above and
finally, computation of the true energy consumption by integrating
the true power, using the time stamps, over all intervals where
the power level is above the `active idle' threshold of 52.5~W.

After incorporating the steps mentioned above in the tests, the
authors of the research paper validated their results. To do so,
they checked if the computed power profile follows the GPU kernel
activity and also they revisited anomalies that they encountered
before in order to check if their new approach eliminates them.
In the end, the profiling almost instantly shoots up when the
kernel starts, stays at a (more or less) constant level during
execution, and almost instantly drops to the aforementioned 52.5 W
after the kernel stops. Importantly, the power level during
execution coincides with the asymptotic power between kernel start
and kernel stop, which verifies the above hypothesis. This
observation gives insight that power should be integrated from the
time point of kernel start to the point of kernel end. Any energy
consumption by the GPU before or after the kernel execution is due
to idling (at different power levels) and is a function of time
but independent of the kernel. In case of anomalies, the first one
was regarding the kernel runtime changes and unintuitive increase
of measured power draw. In the early tests that were based solely
on readings from NVML, after increasing the kernel's runtime by
two times, the power draw readings were not increased
proportionally as well, they were higher by approximately 8\% than
expected. The corrected power profile, however, indicates that, in
fact, the energy consumption increase follows the total runtime
one-to-one, thus resolving this particular anomaly. The second
anomaly was that running the same kernel twice in close temporal
proximity inflates the energy consumption of the second invocation.
Once again, the power profiling proposed by the author clearly
resolves this anomaly as the two corrected profiles are now at the
same level (and the power level between the kernel runs is at the
active-idle level). In other words, the computed power profile of
a kernel is unaffected by prior kernel runs, which is an important
advantage of this approach. This means that there is no need to
have to delay kernel runs until the GPU reaches its idle power
level before one can measure the energy consumption of the next
kernel. Those tests were also validated on other GPUs and the
results showed that they behave in a~similar manner to the first
one. The only notable difference is that all of the measurements
are a few watts higher on the second GPU\@. The difference is,
however, within the 5 W absolute accuracy of the sensor. The
profiled power obtained from tests on other GPUs are all very
similar to each other, which further validates the used methodology.

As a conclusion of this work, many results and insights were
obtained, such as: Power profile is distorted with respect to the
kernel activity; the measured power lags behind the kernel
activity; running multiple kernels one after another inflates the
power draw of the later kernels; after a~short-running kernel, the
power draw can even increase for a while; integrating the power to
a discernable time after a kernel stops does not correctly
compensate for the power lag; the sampling interval lengths vary
greatly; the GPU sensor only performs power measurements once in
a while; the true sampling rate may be too low to accurately
measure short-running kernels and the PCI-bus activity is not
included in the sensor's measurements. This paper proposes and
evaluates a power- and energy-measurement methodology that is
accurate even in the presence of the above problems. It computes
the true instant power consumption from the measured power samples,
accounts for variations in the sampling frequency, and correctly
identifies when kernels are running and when the GPU is in
active-idle mode waiting for the next kernel launch.
